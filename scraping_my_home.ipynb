{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T07:25:40.334990Z",
     "start_time": "2025-09-02T07:25:39.684552Z"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T07:25:42.426373Z",
     "start_time": "2025-09-02T07:25:40.337371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # run in background\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T07:25:42.444246Z",
     "start_time": "2025-09-02T07:25:42.428525Z"
    }
   },
   "outputs": [],
   "source": [
    "# URL and number of pages\n",
    "myhome_url = \"https://www.myhome.ge/s/iyideba-bina-Tbilisshi/?deal_types=1&cities=1&currency_id=1&CardView=1&owner_type=physical&real_estate_types=1&page=\"\n",
    "pages = 10  # number of pages to scrape\n",
    "\n",
    "data = []  # store all listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T07:27:26.534826Z",
     "start_time": "2025-09-02T07:25:42.444246Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(1, pages + 1):\n",
    "    driver.get(myhome_url + str(i))\n",
    "    time.sleep(5)  # wait for JS to render\n",
    "\n",
    "    cards = driver.find_elements(By.CSS_SELECTOR, \"a.group.relative.block\")\n",
    "    # remove cards without title (avoids pagination or extra buttons)\n",
    "    cards = [card for card in cards if len(card.find_elements(By.CSS_SELECTOR, \"h2\")) > 0]\n",
    "\n",
    "    for card in cards:\n",
    "        # URL first\n",
    "        url = card.get_attribute(\"href\") if card.get_attribute(\"href\") else np.nan\n",
    "\n",
    "        # Skip auction listings\n",
    "        if pd.isna(url) or \"auction\" in url:\n",
    "            continue\n",
    "\n",
    "        # Extract property ID from URL\n",
    "        property_id = url.split('/')[4]\n",
    "\n",
    "        # Title\n",
    "        try:\n",
    "            title = card.find_element(By.CSS_SELECTOR, \"h2\").text\n",
    "        except:\n",
    "            title = np.nan\n",
    "\n",
    "        # Price number\n",
    "        try:\n",
    "            price_number = card.find_element(By.CSS_SELECTOR, \"span.truncate\").text\n",
    "        except:\n",
    "            price_number = np.nan\n",
    "            \n",
    "        # Price per square meter\n",
    "        try:\n",
    "            price_per_sqm_span = card.find_element(\n",
    "                By.CSS_SELECTOR, \"div.text-sm.truncate.text-secondary-70 span\"\n",
    "            ).text\n",
    "            # Remove the \" / მ²\" part and convert to float\n",
    "            price_per_sqm = float(price_per_sqm_span.split(\"/\")[0].replace(\",\", \"\").strip())\n",
    "        except:\n",
    "            price_per_sqm = np.nan\n",
    "\n",
    "\n",
    "        # Currency\n",
    "        try:\n",
    "            currency = card.find_element(By.CSS_SELECTOR, \"span.text-secondary-70\").text\n",
    "        except:\n",
    "            currency = np.nan\n",
    "\n",
    "        # Location\n",
    "        try:\n",
    "            location = card.find_element(By.CSS_SELECTOR, \"h3.text-sm\").text\n",
    "        except:\n",
    "            location = np.nan\n",
    "\n",
    "        # District\n",
    "        try:\n",
    "            district = card.find_element(By.CSS_SELECTOR, \"span.font-tbcx-regular\").text\n",
    "        except:\n",
    "            district = np.nan\n",
    "\n",
    "        # Initialize fields\n",
    "        floors = rooms = bedrooms = sqm = np.nan\n",
    "\n",
    "        # -----------------------\n",
    "        # Extract facilities: Floors, Rooms, Bedroom(s), Square meter\n",
    "        # -----------------------\n",
    "        try:\n",
    "            facility_spans = card.find_elements(\n",
    "                By.CSS_SELECTOR,\n",
    "                \"div[class*='facilities--'] div.inline-flex.items-center.gap-1 span\"\n",
    "            )\n",
    "\n",
    "            # Floors\n",
    "            if len(facility_spans) > 0:\n",
    "                floors = facility_spans[0].text if facility_spans[0].text else np.nan\n",
    "\n",
    "            # Rooms\n",
    "            if len(facility_spans) > 1:\n",
    "                rooms = facility_spans[1].text if facility_spans[1].text else np.nan\n",
    "\n",
    "            # Bedrooms\n",
    "            if len(facility_spans) > 2:\n",
    "                # Check if next span is m² symbol (i.e., this is square meters)\n",
    "                parent_div = facility_spans[2].find_element(By.XPATH, \"..\")  # get parent div\n",
    "                spans_in_div = parent_div.find_elements(By.TAG_NAME, \"span\")\n",
    "                if len(spans_in_div) == 2 and spans_in_div[1].text.strip() in [\"მ²\", \"m²\"]:\n",
    "                    bedrooms = np.nan\n",
    "                else:\n",
    "                    bedrooms = facility_spans[2].text.strip()\n",
    "\n",
    "\n",
    "           # Square meter\n",
    "            if len(facility_spans) > 2:\n",
    "                # Check if the second span in this div is m²/მ²\n",
    "                second_span_text = facility_spans[3].text.strip() if len(facility_spans) > 3 else \"\"\n",
    "                if second_span_text in [\"მ²\", \"m²\"]:\n",
    "                    # The number in the 3rd span is square meters\n",
    "                    try:\n",
    "                        sqm = float(facility_spans[2].text.replace(\",\", \".\"))\n",
    "                    except:\n",
    "                        sqm = np.nan\n",
    "                else:\n",
    "                    # Square meters comes from 4th span if exists\n",
    "                    if len(facility_spans) > 3:\n",
    "                        try:\n",
    "                            sqm = float(facility_spans[3].text.replace(\",\", \".\"))\n",
    "                        except:\n",
    "                            sqm = np.nan\n",
    "\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        # Post Date\n",
    "        try:\n",
    "            post_date = card.find_element(\n",
    "                By.CSS_SELECTOR, \"div.flex.items-center.h-full.gap-1.text-secondary-70.text-xs span\"\n",
    "            ).text\n",
    "        except:\n",
    "            post_date = np.nan\n",
    "\n",
    "        # Append all data including property ID, currency, district\n",
    "        data.append([property_id, title, price_number, price_per_sqm, currency, location, district, floors, rooms, bedrooms, sqm, post_date, url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T07:27:26.550614Z",
     "start_time": "2025-09-02T07:27:26.534826Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Save to CSV\n",
    "# with open(\"myhome_listings_en.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow([\"ID\", \"Title\", \"Price\", \"Price per m²\", \"Currency\", \"Location\", \"District\", \"Floors\", \"Rooms\", \"Bedroom(s)\", \"Square meter\", \"Post Date\", \"URL\"])\n",
    "#     writer.writerows(data)\n",
    "\n",
    "# driver.quit()\n",
    "# print(f\"Scraped {len(data)} listings from {pages} pages!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T07:27:26.565920Z",
     "start_time": "2025-09-02T07:27:26.551611Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure the folder exists\n",
    "os.makedirs(\"data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T07:27:26.581635Z",
     "start_time": "2025-09-02T07:27:26.567920Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert scraped data to DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"ID\", \"Title\", \"Price\", \"Price per m²\", \"Currency\", \n",
    "                                 \"Location\", \"District\", \"Floors\", \"Rooms\", \n",
    "                                 \"Bedroom(s)\", \"Square meter\", \"Post Date\", \"URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T07:27:26.588758Z",
     "start_time": "2025-09-02T07:27:26.582518Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Save CSV in the data folder\n",
    "# csv_path = os.path.join(\"data\", \"myhome_listings_en.csv\")\n",
    "# df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# driver.quit()\n",
    "# print(f\"Scraped {len(data)} listings from {pages} pages! Saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T07:27:26.603975Z",
     "start_time": "2025-09-02T07:27:26.589756Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add timestamp and pages to filename\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_filename = f\"myhome_listings_en_{timestamp}_pages{pages}.csv\"\n",
    "csv_path = os.path.join(\"data\", csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T07:27:28.785630Z",
     "start_time": "2025-09-02T07:27:26.604966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 200 listings from 10 pages! Saved to data\\myhome_listings_en_20250902_112726_pages10.csv\n"
     ]
    }
   ],
   "source": [
    "# Save CSV\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "driver.quit()\n",
    "print(f\"Scraped {len(data)} listings from {pages} pages! Saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
